{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italian-clock",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opened-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from image_classification.preprocessors.basic import preprocessor as test_preprocessor\n",
    "from image_classification.preprocessors.jitter_rotate_flip import preprocessor as train_preprocessor\n",
    "from image_classification.datasets.fashion_mnist import FashionMNIST\n",
    "from image_classification.models.vgg import vgg11_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "external-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-choir",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extensive-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "split = 50000\n",
    "batch_size = 128\n",
    "data_dir = \"../data/fashion_mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-disco",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitting-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-affairs",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooperative-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(is_train=True, data_dir=data_dir, transform=train_preprocessor)\n",
    "eval_dataset = FashionMNIST(is_train=True, data_dir=data_dir, transform=test_preprocessor)\n",
    "test_dataset = FashionMNIST(is_train=False, data_dir=data_dir, transform=test_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "external-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6878ac-4c72-4bb6-a1e2-4c8bc7d94e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(len(train_dataset))\n",
    "train_indices, eval_indices = indices[:split], indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "eval_sampler = SubsetRandomSampler(eval_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "orange-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size, sampler=train_sampler)\n",
    "eval_dl = DataLoader(eval_dataset, batch_size*2, sampler=eval_sampler)\n",
    "test_dl = DataLoader(test_dataset, batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d39017a-184b-41ec-a381-f10dfa289ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50048, 10240, 10240)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)*batch_size, len(eval_dl)*batch_size*2, len(test_dl)*batch_size*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, labels = next(iter(train_dl))\n",
    "batch.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-industry",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "competitive-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_dim: int, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=out_dim)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legendary-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opened-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels=1, out_dim=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "multiple-sapphire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-coordination",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floral-championship",
   "metadata": {
    "papermill": {
     "duration": 0.0428,
     "end_time": "2021-04-18T13:56:12.026304",
     "exception": false,
     "start_time": "2021-04-18T13:56:11.983504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas=(0.9,0.999), eps=1e-9)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1, verbose=False)\n",
    "###Best accuracy 0.9349, tensor(0.9385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conditional-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "examples_seen = 0\n",
    "eval_interval = 100\n",
    "model.train()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "least-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#0 Examples seen: 128\tEval accuracy: 0.100390625\tEval loss: 3.2527753531932833\t\n",
      "Epoch#0 Examples seen: 12928\tEval accuracy: 0.6650390625\tEval loss: 0.9320821195840836\t\n",
      "Epoch#0 Examples seen: 25728\tEval accuracy: 0.69521484375\tEval loss: 0.8198227941989898\t\n",
      "Epoch#0 Examples seen: 38528\tEval accuracy: 0.7244140625\tEval loss: 0.7340614274144173\t\n",
      "Epoch#1 Examples seen: 50176\tEval accuracy: 0.7275390625\tEval loss: 0.7289986088871956\t\n",
      "Epoch#1 Examples seen: 62976\tEval accuracy: 0.7349609375\tEval loss: 0.7206683188676835\t\n",
      "Epoch#1 Examples seen: 75776\tEval accuracy: 0.74873046875\tEval loss: 0.6602572843432426\t\n",
      "Epoch#1 Examples seen: 88576\tEval accuracy: 0.716015625\tEval loss: 0.779403293132782\t\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        examples_seen += batch_size\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i%eval_interval==0:\n",
    "            losses, accuracies = [], []\n",
    "            for x, y in eval_dl:\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(x)\n",
    "                    loss = criterion(y_pred, y).item()\n",
    "                    accuracy = (y_pred.argmax(axis=1)==y).float().mean().item()\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "            eval_loss = np.mean(losses)\n",
    "            eval_accuracy = np.mean(accuracies)\n",
    "            print(\n",
    "                f\"Epoch#{epoch} \"\n",
    "                f\"Examples seen: {examples_seen}\\t\"\n",
    "                f\"Eval accuracy: {eval_accuracy}\\t\"\n",
    "                f\"Eval loss: {eval_loss}\\t\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "prompt-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.mean([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d744d-cb7c-450e-9eb4-79939827d6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('venv': venv)",
   "language": "python",
   "name": "python375jvsc74a57bd0b8616ea29f167952103aaf3891f5a8d38faff850b2dc4af3c9217394862bfe2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
